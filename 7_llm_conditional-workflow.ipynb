{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "066481eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,START, END\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict,Annotated, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "721d9e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f80709dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model='gemini-2.5-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "44ee531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentSchema(BaseModel):\n",
    "\n",
    "    sentiment: Literal['positive', 'negative'] = Field(description='sentiment of the review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2e5df476",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiagnosisSchema(BaseModel):\n",
    "    issue_type: Literal[\"UX\", \"Performance\", \"Bug\", \"Support\", \"Other\"] = Field(description='The category of issue mentioned in the review')\n",
    "    tone: Literal[\"angry\", \"frustrated\", \"disappointed\", \"calm\"] = Field(description='The emotional tone expressed by the user')\n",
    "    urgency: Literal[\"low\", \"medium\", \"high\"] = Field(description='How urgent or critical the issue appears to be')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1240a38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_model = model.with_structured_output(SentimentSchema)\n",
    "structured_model_diagnosis = model.with_structured_output(DiagnosisSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "781779dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentiState(TypedDict):\n",
    "\n",
    "    review: str\n",
    "\n",
    "    sentiment: Literal['positive', 'negative']\n",
    "    diagnosis: dict\n",
    "    response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b97729ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sentiment(state: SentiState):\n",
    "\n",
    "    prompt = f'for the following review find the sentiment \\n {state[\"review\"]}'\n",
    "    sentiment = structured_model.invoke(prompt).sentiment\n",
    "\n",
    "    return {'sentiment': sentiment}\n",
    "\n",
    "def check_sentiment(state: SentiState) -> Literal['positive_response', 'run_diagnosis']:\n",
    "\n",
    "    if state['sentiment'] == 'positive':\n",
    "        return 'positive_response'\n",
    "    else:\n",
    "        return 'run_diagnosis'\n",
    "    \n",
    "def positive_response(state: SentiState):\n",
    "    prompt = f'write a thank you message in response to this review \\n {state[\"review\"]}.  Do not explain or give multiple options. Just return a single message.'\n",
    "    response = model.invoke(prompt).content\n",
    "    return {'response': response}\n",
    "\n",
    "def run_diagnosis(state: SentiState):\n",
    "\n",
    "    prompt = f\"\"\"Diagnose this negative review:\\n\\n{state['review']}\\n\"\n",
    "    \"Return issue_type, tone, and urgency.\n",
    "\"\"\"\n",
    "    \n",
    "    diagnosis = structured_model_diagnosis.invoke(prompt)\n",
    "\n",
    "    return {'diagnosis': diagnosis.model_dump()}\n",
    "\n",
    "def negative_response(state: SentiState):\n",
    "\n",
    "    diagnosis = state['diagnosis']\n",
    "\n",
    "    prompt = f\"\"\"You are a support assistant.\n",
    "The user had a '{diagnosis['issue_type']}' issue, sounded '{diagnosis['tone']}', and marked urgency as '{diagnosis['urgency']}'.\n",
    "Write an empathetic, helpful resolution message.  Do not explain or give multiple options. Just return a single message.\"\"\"\n",
    "    \n",
    "    response = model.invoke(prompt).content\n",
    "\n",
    "    return {\"response\": response}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "fce67c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(SentiState)\n",
    "\n",
    "graph.add_node('find_sentiment', find_sentiment)\n",
    "graph.add_node('check_sentiment', check_sentiment)\n",
    "graph.add_node('positive_response', positive_response)\n",
    "graph.add_node('run_diagnosis', run_diagnosis)\n",
    "graph.add_node('negative_response', negative_response)\n",
    "\n",
    "\n",
    "graph.add_edge(START, 'find_sentiment')\n",
    "graph.add_conditional_edges('find_sentiment', check_sentiment)\n",
    "graph.add_edge('positive_response', END)\n",
    "graph.add_edge('run_diagnosis', 'negative_response')\n",
    "graph.add_edge('negative_response', END)\n",
    "\n",
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2c79f0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'review': 'i have never seen such a beautiful design like this and website performance is fast', 'sentiment': 'positive', 'response': \"Thank you so much for your incredibly kind words! We're thrilled that you love the design and are enjoying the fast performance, as that's exactly the experience we aim to create.\"}\n"
     ]
    }
   ],
   "source": [
    "initial_state = {'review': 'i have never seen such a beautiful design like this and website performance is fast'}\n",
    "final_state = workflow.invoke(initial_state)\n",
    "print(final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dfd0fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78c8386a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
